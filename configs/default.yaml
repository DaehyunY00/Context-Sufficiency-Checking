run:
  language: "ko"
  seed: 42
  seed_list: [42, 43, 44]
  device_preference: ["mps", "cpu"]
  force_mps: false
  hf_cache_dir: ".hf_cache"
  output_dir: "outputs"
  log_jsonl: true

dataset:
  name: "hotpotqa"
  # 2Wiki를 사용할 경우 예:
  # name: "2wikimultihopqa"
  # hf_name: "scholarly-shadows-syndicate/2wikimultihopqa"
  # hf_config: null
  split: "validation"
  max_questions: 500
  corpus_chunk:
    chunk_size: 300
    chunk_overlap: 50

retrieval:
  embed_model: "intfloat/e5-small-v2"
  index_type: "faiss_cpu"
  top_k_initial: 3
  top_k_reretrieve: 6

generator:
  model_name: "google/flan-t5-large"
  max_input_length: 1024
  max_new_tokens: 32
  temperature: 0.2
  do_sample: false
  prompt_style: "qa_short_ko"
  abstain_text: "모르겠습니다."

autorater:
  enabled: true
  model_name: "google/flan-t5-large"
  max_input_length: 1024
  max_new_tokens: 96
  temperature: 0.0
  do_sample: false
  output_format: "json_one_line"
  parse_fail_policy: "insufficient"
  max_parse_retries: 1
  max_context_chars: 1800
  prompt_template: "templates/autorater_ko.txt"

sufficiency:
  checker: "heuristic"
  heuristic:
    min_keyword_hits: 2
    min_coverage_ratio: 0.5
  self_consistency:
    n_samples: 5
    temperature: 0.7
    disagreement_threshold: 0.6
    stability:
      enabled: true
      compare_samples: [3, 5]
  entailment:
    enabled: false
    model_name: "roberta-base-mnli"
    sufficient_if_entail_prob_ge: 0.6

strategy:
  mode: "abstain"
  hybrid:
    reretrieve_then_abstain: true
  uncertainty:
    metric: "avg_token_prob"
    threshold: 0.20
    logprob_threshold: 0.20
    entropy_threshold: 0.35
  policy_optimization:
    enabled: true
    hallucination_weight: 1.0
    abstain_weight: 0.3
    latency_weight: 0.0
    latency_scale_ms: 1000.0

evaluation:
  metrics: ["em", "f1", "hallucination_rate", "coverage", "selective_accuracy", "latency_ms", "aurc"]
  calibration_bins: 10
  calibration:
    temperature_scaling:
      enabled: true
      validation_ratio: 0.3
      seed: 42
      min_samples: 50
  latency:
    warmup_drop: 5
    hist_bins: 30
  answerable:
    mode: "gold_containment"  # gold_containment | entailment
    entail_model_name: "roberta-base-mnli"
    entail_prob_threshold: 0.6
  bootstrap:
    enabled: true
    n_samples: 1000
    confidence_level: 0.95

report:
  format: "markdown_ko"
  save_csv: true
  save_markdown: true
